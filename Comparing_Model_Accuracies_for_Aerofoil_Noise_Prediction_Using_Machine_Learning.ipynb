# -*- coding: utf-8 -*-
"""Comparing-Model-Accuracies-for-Aerofoil-Noise-Using-Machine-Learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nHCPQ3Z7-cxayv3-MW-ph_XKhawWiZTL
"""

from google.colab import files
uploaded = files.upload()
import pandas as pd
import io
for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))
  # Specify the encoding, delimiter, and quoting when reading the CSV
  df = pd.read_csv(
      io.BytesIO(uploaded[fn]),
      encoding='latin-1',
      delimiter=',',
      quotechar='"',

      on_bad_lines='skip',
  )

df

df.columns

df.dtypes

print(df.head())

print(df.info())

print(df.describe())

import seaborn as sns
import matplotlib.pyplot as plt

# Histograms for all numerical features
df.hist(figsize=(12, 8), bins=30)
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(6,4))
sns.scatterplot(x=df['f'], y=df['SSPL'])
plt.xlabel("f")
plt.ylabel("SSPL")
plt.title("Scatter Plot of f vs SSPL")
plt.show()


plt.figure(figsize=(6,4))
sns.violinplot(y=df['SSPL'], color='green')
plt.ylabel("SSPL")
plt.title("Violin Plot of SSPL")
plt.show()



plt.figure(figsize=(8,5))
sns.barplot(x=df['alpha'], y=df['delta'], ci=None)  # ci=None removes confidence intervals
plt.xlabel("Alpha")
plt.ylabel("Delta")
plt.title("Bar Chart of Alpha vs Delta")
plt.xticks(rotation=45)  # Rotate x-axis labels if needed
plt.show()

import seaborn as sns
import matplotlib.pyplot as plt

plt.figure(figsize=(8,5))
sns.histplot(df['SSPL'], bins=30, kde=True, color='blue')  # KDE adds a smooth density curve
plt.xlabel("SSPL")
plt.ylabel("Frequency")
plt.title("Histogram of SSPL")
plt.show()

u_infinity_counts = df['U_infinity'].value_counts()
print("Counts of unique values in U_infinity:\n", u_infinity_counts)

unique_u_infinity = df['U_infinity'].nunique()
print(f"Number of unique values in U_infinity: {unique_u_infinity}")

unique_c = df['c'].nunique()
print(f"Number of unique values in 'c': {unique_c}")

c_counts = df['c'].value_counts()
print("Counts of unique values in 'c':\n", c_counts)

df.columns

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error
import xgboost as xgb

# Assuming df is your DataFrame
X = df[['f', 'alpha', 'c', 'U_infinity', 'delta']]  # Replace with your features
y = df['SSPL']  # Replace with your target variable

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize models
linear_regressor = LinearRegression()
rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)
xgb_regressor = xgb.XGBRegressor(n_estimators=100, random_state=42)

# Train models
linear_regressor.fit(X_train, y_train)
rf_regressor.fit(X_train, y_train)
xgb_regressor.fit(X_train, y_train)

# Make predictions
y_pred_linear = linear_regressor.predict(X_test)
y_pred_rf = rf_regressor.predict(X_test)
y_pred_xgb = xgb_regressor.predict(X_test)

# Evaluate models
mse_linear = mean_squared_error(y_test, y_pred_linear)
mse_rf = mean_squared_error(y_test, y_pred_rf)
mse_xgb = mean_squared_error(y_test, y_pred_xgb)

print(f"Linear Regression MSE: {mse_linear}")
print(f"Random Forest MSE: {mse_rf}")
print(f"XGBoost MSE: {mse_xgb}")

# Plot the actual vs predicted values for each model
plt.figure(figsize=(14, 6))

# Linear Regression plot
plt.subplot(1, 3, 1)
plt.scatter(y_test, y_pred_linear)
plt.xlabel("Actual SSPL")
plt.ylabel("Predicted SSPL")
plt.title("Linear Regression: Actual vs. Predicted")

# Random Forest plot
plt.subplot(1, 3, 2)
plt.scatter(y_test, y_pred_rf)
plt.xlabel("Actual SSPL")
plt.ylabel("Predicted SSPL")
plt.title("Random Forest: Actual vs. Predicted")

# XGBoost plot
plt.subplot(1, 3, 3)
plt.scatter(y_test, y_pred_xgb)
plt.xlabel("Actual SSPL")
plt.ylabel("Predicted SSPL")
plt.title("XGBoost: Actual vs. Predicted")

# Display the plots
plt.tight_layout()
plt.show()
